{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"1.3-demo_1D.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"gxnvml6gbuZY","colab_type":"text"},"source":["### 1. Import dei pachetti necessari\n"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"su7IMZL3buZe","colab_type":"code","colab":{}},"source":["import sounddevice as sd\n","from scipy.io.wavfile import write\n","import speech_recognition as sr\n","from gtts import gTTS\n","import time\n","import playsound\n","import librosa\n","import PySimpleGUI as sg\n","import numpy as np\n","import os\n","import librosa\n","import sys\n","from keras.models import load_model\n","import cv2 as cv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O_Y-eJS2buZx","colab_type":"text"},"source":["### 2. Definizione delle funzioni \n","- *crop*: per portrare il segnale nella dimesnione standard\n","- *wav2mfcc*: per estrarre dal segnale il Mel-frequency cepstral coefficients\n","- *main*: per generare le predizioni\n","- *speak*: API servita da Google per generare suono partendo dal testo"]},{"cell_type":"code","metadata":{"id":"uNQzNLUfbuZ0","colab_type":"code","colab":{}},"source":["def crop(input, size):\n","    # Elimina eventuali valori oltre il numero consentito\n","    output = input[0:min(size, input.shape[0])]\n","    # Aggiungi valori nulli per raggiungere la dimensione richiesta\n","    output = np.concatenate((output, np.zeros(size-output.shape[0])))\n","    return output\n","\n","\n","def wav2mfcc(file_path, max_len=40):\n","  seconds=3\n","  wave, sr = librosa.load(file_path, mono=True, sr=44100)\n","  wave = crop(wave, sr*seconds)\n","  mfcc = librosa.feature.mfcc(wave, sr=sr, n_fft=2048, hop_length=512, n_mfcc=40)\n","  return mfcc\n","\n","\n","def main(input, model):\n","    \n","    dict_comm = {\"okgoogle\": 0, \"heysiri\": 1, \"alexa\":2}\n","    \n","    #estraggo le features\n","    X = wav2mfcc(input)\n","    X = X.reshape(-1,40,259,1)\n","    \n","    y_ana = np.argmax(model.predict(X)[0], axis=1)[0]\n","    y_fede = np.argmax(model.predict(X)[1], axis=1)[0]\n","    y_da = np.argmax(model.predict(X)[2], axis=1)[0]\n","\n","    y_va = np.argmax(model.predict(X)[3], axis=1)[0]\n","    vocal_assistant = list(dict_comm.keys())[y_va]\n","    \n","    #subject = str()\n","    \n","    if y_ana==0 and y_fede==0 and y_da==0:\n","        subject = 'Sconosciuto'\n","    elif y_ana==1 and y_fede==0 and y_da==0:\n","        subject = 'Anastasia'\n","    elif y_ana==0 and y_fede==1 and y_da==0:\n","        subject = 'Federico'\n","    elif y_ana==0 and y_fede==0 and y_da==1:\n","        subject = 'Davide'\n","    elif y_ana==0 and y_fede==1 and y_da==1:\n","        subject = 'Sconosciuto'\n","        \n","    if vocal_assistant=='alexa':\n","        vocal_assistant='Alexa'\n","    elif vocal_assistant=='okgoogle':\n","        vocal_assistant='Google'\n","    else:\n","        vocal_assistant='Siri'\n","\n","    return subject, vocal_assistant\n","    \n","\n","def speak(text):\n","    tts = gTTS(text=text, lang='it')\n","    filename = 'reply.mp3'\n","    tts.save(filename)\n","    playsound.playsound(filename)\n","    os.remove(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_KG6wF-buaD","colab_type":"text"},"source":["### 3. Demo live"]},{"cell_type":"code","metadata":{"id":"Z3V3Qq6JbuaG","colab_type":"code","colab":{},"outputId":"13d9102c-8ddd-45fa-e4d2-9d4aa2f6f2f7"},"source":["#importo il modello da directory\n","%time model = load_model('model_processing1D')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wall time: 13.4 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tQzFV_a9buaY","colab_type":"code","colab":{}},"source":["duration = 3\n","rec_rate = 44100\n","\n","cap = cv.VideoCapture(0)\n","status=\"\"\n","f=\"Premere 'r' per registrare o 'Esc' per uscire\"\n","\n","while(True):\n","\n","    r, frame = cap.read()\n","    cv.putText(frame, f, (15, 37), cv.FONT_HERSHEY_SIMPLEX, 0.75, (255,255,255), 2)\n","    cv.imshow('Riconoscimento identita\\' soggetto e comando vocale', frame)\n","    \n","    # Registra premendo il tasto R\n","    if cv.waitKey(20) & 0xFF == ord('r'):\n","        f = 'Inizio a registrare...'\n","        audio = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1)\n","        sd.wait(3)\n","\n","        write('temp.wav', rate=rec_rate, data=audio)\n","\n","        subject_, vocal_assistant_ = main('temp.wav', model)\n","        os.remove('temp.wav')\n","\n","        if subject_== 'Sconosciuto':\n","            output_text = \"Ciao sono \"+ vocal_assistant_ + \", ci conosciamo?\"\n","        else:\n","            output_text = 'Ciao ' + subject_ + \", sono \" + vocal_assistant_\n","            \n","        try:\n","            f = output_text\n","            speak(output_text)\n","        except:\n","            pass\n","        \n","    k = cv.waitKey(10) & 0xff\n","    if k == 27: # press 'ESC' to quit\n","        break\n","        \n","cap.release()\n","cv.destroyAllWindows()"],"execution_count":null,"outputs":[]}]}